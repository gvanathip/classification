{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN4J+uQ3BSpzfiepE8inkn/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gvanathip/classification/blob/main/remove_multicollinearity_with_NetworkX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset and Clean Process :\n",
        "https://www.kaggle.com/code/iyet1killer/classification-on-categorical-data-part-1-sklearn/notebook"
      ],
      "metadata": {
        "id": "3y6GXUg-V93d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "GbgsU8PlZJi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('in-vehicle-coupon-recommendation.csv')"
      ],
      "metadata": {
        "id": "heGMb64OWZsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "t-4VFUvFZNGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ultimate Data Processing Function\n",
        "def data_cleaning(data=df):\n",
        "    clean_df = df.copy()\n",
        "\n",
        "    clean_df.drop(columns=['car'], inplace=True)\n",
        "    na_columns = ['Bar', 'CoffeeHouse', 'CarryAway', 'RestaurantLessThan20', 'Restaurant20To50']\n",
        "    clean_df.drop(columns=['toCoupon_GEQ5min'], inplace=True)\n",
        "    frequency_map = {\n",
        "        'never': 0,\n",
        "        'less1': 1,\n",
        "        '1~3': 2,\n",
        "        '4~8': 3,\n",
        "        'gt8': 4}\n",
        "    age_map = {\n",
        "        'below21': 0,\n",
        "        '21': 1,\n",
        "        '26': 2,\n",
        "        '31': 3,\n",
        "        '36': 4,\n",
        "        '41': 5,\n",
        "        '46': 6,\n",
        "        '50plus': 7}\n",
        "    income_map = {\n",
        "        'Less than $12500': 0,\n",
        "        '$12500 - $24999': 1,\n",
        "        '$25000 - $37499': 2,\n",
        "        '$37500 - $49999': 3,\n",
        "        '$50000 - $62499': 4,\n",
        "        '$62500 - $74999': 5,\n",
        "        '$75000 - $87499': 6,\n",
        "        '$87500 - $99999': 7,\n",
        "        '$100000 or More': 8}\n",
        "    frequency_cols = ['Restaurant20To50', 'RestaurantLessThan20',\n",
        "                      'CarryAway', 'CoffeeHouse', 'Bar']\n",
        "    for col in frequency_cols:\n",
        "        clean_df[col] = clean_df[col].map(frequency_map)\n",
        "    clean_df.age = clean_df.age.map(age_map)\n",
        "    clean_df.income = clean_df.income.map(income_map)\n",
        "    clean_df.drop(columns=['direction_opp'], inplace=True)\n",
        "    clean_df['distance'] = None\n",
        "    clean_df.loc[clean_df['toCoupon_GEQ15min'] == 0, 'distance'] = 0\n",
        "    clean_df.loc[(clean_df['toCoupon_GEQ15min'] == 1) & \\\n",
        "                 (clean_df['toCoupon_GEQ25min'] == 0), 'distance'] = 1\n",
        "    clean_df.loc[clean_df['toCoupon_GEQ25min'] == 1, 'distance'] = 2\n",
        "    clean_df.distance = clean_df.distance.astype('int64')\n",
        "    clean_df.drop(columns=['toCoupon_GEQ15min', 'toCoupon_GEQ25min'], inplace=True)\n",
        "    clean_df.has_children = clean_df.has_children.astype(str)\n",
        "    clean_df.direction_same = clean_df.direction_same.astype(str)\n",
        "    return clean_df"
      ],
      "metadata": {
        "id": "U1BlKoirXR53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = data_cleaning(df)"
      ],
      "metadata": {
        "id": "sqrzEmVDTXaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "BoeAbJm6an7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "L1up1Mp8TrZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['Y'])['Y'].count()"
      ],
      "metadata": {
        "id": "9h7oxiAPTZCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41MeJK20LxMP"
      },
      "outputs": [],
      "source": [
        "num_cols = sorted(list(df.select_dtypes(include=\"number\").columns))\n",
        "cate_cols = sorted(list(df.select_dtypes(exclude=\"number\").columns))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[num_cols] = df[num_cols].fillna(0)\n",
        "df[cate_cols] = df[cate_cols].fillna('-')"
      ],
      "metadata": {
        "id": "eKAztPSiN1b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cate_cols.append('Y')"
      ],
      "metadata": {
        "id": "l-kd2_lCN2M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cor = df[num_cols].corr()\n",
        "cor = pd.DataFrame(cor.unstack()).reset_index().rename(columns={\"level_0\": \"x1\", \"level_1\": \"x2\", 0: \"r\"})\n",
        "cor['abs_r'] = abs(cor.r)\n",
        "cor_y = dict(zip(cor[cor.x1=='Y'].x2,cor[cor.x1=='Y'].abs_r))"
      ],
      "metadata": {
        "id": "amkyA4Xlbv-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cor.abs_r.hist()"
      ],
      "metadata": {
        "id": "O0gN9xSWbX-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_cor = cor[cor.abs_r > 0.2]\n",
        "h_cor = h_cor[h_cor.x1 != h_cor.x2]"
      ],
      "metadata": {
        "id": "-a2rvBSfNCv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_cor"
      ],
      "metadata": {
        "id": "yW19rrQGbUe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx"
      ],
      "metadata": {
        "id": "z29_EFRuOC0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.from_pandas_edgelist(h_cor, 'x1', 'x2', ['abs_r'])\n",
        "# G.remove_node('Y')\n",
        "G = G.to_undirected()"
      ],
      "metadata": {
        "id": "Yt5r-8lIOMVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "nx.draw(G,with_labels=True, font_size=6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t7C4N0FUORog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnx = []\n",
        "for i in sorted(set(h_cor.x1).union(set(h_cor.x2))):\n",
        "#     print(i)\n",
        "\n",
        "    if list(sorted(nx.node_connected_component(G,i))) in rnx:\n",
        "        continue\n",
        "    else:\n",
        "#         print(list(sorted(nx.node_connected_component(G,i))))\n",
        "        rnx.append(list(nx.node_connected_component(G,i)))\n",
        "#         print('/////////////////////////')"
      ],
      "metadata": {
        "id": "yO0Al-NXOdF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_nx = []\n",
        "for i in rnx:\n",
        "    if sorted(i) in r_nx:\n",
        "        continue\n",
        "    else:\n",
        "        r_nx.append(sorted(i))\n",
        "#         print(sorted(i))"
      ],
      "metadata": {
        "id": "bNY9ug7SOivm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = 1\n",
        "# ls = []\n",
        "lss = dict()\n",
        "\n",
        "for k in r_nx:\n",
        "    lss[g] = k\n",
        "    g = g+1"
      ],
      "metadata": {
        "id": "es-IyubgOoNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_cor_y = pd.DataFrame()\n",
        "g = []\n",
        "x = []\n",
        "abs_cor_y = []\n",
        "\n",
        "for ls in lss:\n",
        "#     print(ls)\n",
        "    for i in lss[ls]:\n",
        "        g.append(ls)\n",
        "        x.append(i)\n",
        "        abs_cor_y.append(cor_y[i])\n",
        "#             print(ls, i, cor_y[i])\n",
        "#         print(lss[ls])\n",
        "h_cor_y = pd.DataFrame(list(zip(g, x, abs_cor_y)),columns =['group', 'x', 'abs_cor_with_y'])"
      ],
      "metadata": {
        "id": "qSoflEWCOuOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_cor_y['rank'] = h_cor_y.groupby('group')['abs_cor_with_y'].rank(ascending=False)\n",
        "drop_h_cor_cols = list(set(h_cor_y[h_cor_y['rank'] > 1].x))"
      ],
      "metadata": {
        "id": "JmPuEjo_O157"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_cor_y"
      ],
      "metadata": {
        "id": "IrHznUY4PIqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_h_cor_cols"
      ],
      "metadata": {
        "id": "djLw8Ez5PBZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "x1 = []\n",
        "x2 = []\n",
        "chi = []\n",
        "pv = []\n",
        "from scipy.stats import chi2_contingency\n",
        "for i in tqdm(cate_cols):\n",
        "    for j in cate_cols:\n",
        "        if i != j:\n",
        "#             print(i,':',j)\n",
        "            x1.append(i)\n",
        "            x2.append(j)\n",
        "            CrosstabResult=pd.crosstab(df[i], df[j])\n",
        "            try:\n",
        "                ChiSqResult = chi2_contingency(CrosstabResult)\n",
        "                chi.append(ChiSqResult[0])\n",
        "                pv.append(ChiSqResult[1])\n",
        "#                 if ChiSqResult[1] < 0.05:\n",
        "#                     print(i,':',j)\n",
        "#                     print('The P-Value of the ChiSq Test is:', ChiSqResult[1])\n",
        "            except:\n",
        "#                 chi.append(0)\n",
        "                continue"
      ],
      "metadata": {
        "id": "4gDOJMTZPhm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chi_df = pd.DataFrame(list(zip(x1, x2, chi, pv)),columns =['x1', 'x2', 'chi', 'pvalue'])"
      ],
      "metadata": {
        "id": "az8VmA4wZyYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chi_df[chi_df.x1 == 'Y']\n",
        "\n",
        "# sm_cor_y = dict(zip(chi_df[chi_df.x1 == 'Y'].x2,chi_df[chi_df.x1 == 'Y'].chi))\n",
        "sm_cor_y = chi_df[chi_df.x1 == 'Y']"
      ],
      "metadata": {
        "id": "OV4QKR0iZ5Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_cate_cols = chi_df[(chi_df.pvalue > 0.5) & (chi_df.x1 != 'Y') & (chi_df.x2 != 'Y') & (chi_df.x2 != chi_df.x1)]"
      ],
      "metadata": {
        "id": "yT00sLrWZ9aC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_cate_cols"
      ],
      "metadata": {
        "id": "kGFQ7rJ_cO9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G2 = nx.from_pandas_edgelist(h_cate_cols, 'x1', 'x2', ['pvalue'])\n",
        "# G2.remove_node('Y')\n",
        "G2 = G2.to_undirected()"
      ],
      "metadata": {
        "id": "2NL9MRo0aCe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx.draw(G2,with_labels=True, font_size=6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PpwuhYd8aCqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(set(h_cate_cols.x1).union(set(h_cate_cols.x2)))"
      ],
      "metadata": {
        "id": "qHVkoEedcK_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cate_cols"
      ],
      "metadata": {
        "id": "XUXxvFn5cVd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for categorical variables most of them quite high correlation, so try to sub group with column name distance, for real world complex data for example 'price_tier1', 'price_tier2', 'price_tier3'\n",
        "\n",
        "if it doesn't make sense, will not neccesary to execute."
      ],
      "metadata": {
        "id": "sBMjjnT2c1-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnx = []\n",
        "for i in sorted(set(h_cate_cols.x1).union(set(h_cate_cols.x2))):\n",
        "#     print(i)\n",
        "\n",
        "    if list(sorted(nx.node_connected_component(G2,i))) in cnx:\n",
        "        continue\n",
        "    else:\n",
        "#         print(list(sorted(nx.node_connected_component(G2,i))))\n",
        "        cnx.append(list(nx.node_connected_component(G2,i)))\n",
        "#         print('/////////////////////////')"
      ],
      "metadata": {
        "id": "3w-_uybZcnAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_nx = []\n",
        "for i in cnx:\n",
        "    if sorted(i) in c_nx:\n",
        "        continue\n",
        "    else:\n",
        "        c_nx.append(sorted(i))\n",
        "#         print(sorted(i))"
      ],
      "metadata": {
        "id": "N0aXWm32dmiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = 1\n",
        "# ls = []\n",
        "lsc = dict()\n",
        "\n",
        "for k in c_nx:\n",
        "    lsc[g] = k\n",
        "    g = g+1"
      ],
      "metadata": {
        "id": "Zb2dgVNvduAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_nx = [j for i in c_nx for j in i]"
      ],
      "metadata": {
        "id": "ewWBm16Cd0CJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_binary(list1,list2):\n",
        "    intersection = len(list(set(list1).intersection(set(list2))))\n",
        "    union = len(list(set(list1).union(set(list2))))\n",
        "    return float(intersection) / union"
      ],
      "metadata": {
        "id": "CU0ak0MId54h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x3 = []\n",
        "x4 = []\n",
        "sm = []\n",
        "for i in c_nx:\n",
        "    for j in c_nx:\n",
        "        if i != j:\n",
        "            # Convert the texts into TF-IDF vectors\n",
        "            x3.append(i)\n",
        "            x4.append(j)\n",
        "\n",
        "            similarity = jaccard_binary([char for char in i],[char for char in j])\n",
        "            sm.append(similarity)\n",
        "#             print(i,j,similarity)"
      ],
      "metadata": {
        "id": "I3ocGZa-eLCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm_df = pd.DataFrame(list(zip(x3, x4, sm)),columns =['x1', 'x2', 'similarity'])"
      ],
      "metadata": {
        "id": "EZakDPlHeQtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm_df.similarity.hist()"
      ],
      "metadata": {
        "id": "X0_vqM-uea_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_sm_col_df = sm_df[sm_df.similarity > 0.6]"
      ],
      "metadata": {
        "id": "1IeYN_lneV4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_sm_col_df"
      ],
      "metadata": {
        "id": "NjJ7LWdherkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G3 = nx.from_pandas_edgelist(h_sm_col_df, 'x1', 'x2', ['similarity'])\n",
        "# G2.remove_node('Y')\n",
        "G3 = G3.to_undirected()"
      ],
      "metadata": {
        "id": "c7uZafIuetkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nx.draw(G3,with_labels=True, font_size=6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dYDfg0lqe5Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smnx = []\n",
        "for i in sorted(set(h_sm_col_df.x1).union(set(h_sm_col_df.x2))):\n",
        "#     print(i)\n",
        "\n",
        "    if list(sorted(nx.node_connected_component(G3,i))) in smnx:\n",
        "        continue\n",
        "    else:\n",
        "#         print(list(sorted(nx.node_connected_component(G3,i))))\n",
        "        smnx.append(list(nx.node_connected_component(G3,i)))\n",
        "#         print('/////////////////////////')"
      ],
      "metadata": {
        "id": "yA-RLkr_e-j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm_nx = []\n",
        "for i in smnx:\n",
        "    if sorted(i) in sm_nx:\n",
        "        continue\n",
        "    else:\n",
        "        sm_nx.append(sorted(i))\n",
        "#         print(sorted(i))"
      ],
      "metadata": {
        "id": "9vzPJyTwfj-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = 1\n",
        "# ls = []\n",
        "lssm = dict()\n",
        "\n",
        "for k in sm_nx:\n",
        "    lssm[g] = k\n",
        "    g = g+1"
      ],
      "metadata": {
        "id": "RK0GJOW2fouk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_sm_cor_y = pd.DataFrame()\n",
        "g = []\n",
        "x = []\n",
        "chi_cor_y = []\n",
        "pv_cor_y = []\n",
        "\n",
        "for ls in lssm:\n",
        "#     print(ls)\n",
        "    for i in lssm[ls]:\n",
        "        g.append(ls)\n",
        "        x.append(i)\n",
        "        try:\n",
        "            chi_cor_y.append(sm_cor_y[sm_cor_y.x2 == i].chi.values[0])\n",
        "            pv_cor_y.append(sm_cor_y[sm_cor_y.x2 == i].pvalue.values[0])\n",
        "        except:\n",
        "            chi_cor_y.append(0)\n",
        "            pv_cor_y.append(0)\n",
        "#             print(ls, i, cor_y[i])\n",
        "#         print(lss[ls])\n",
        "h_sm_cor_y = pd.DataFrame(list(zip(g, x, chi_cor_y, pv_cor_y)),columns =['group', 'x', 'chi_with_y', 'pvalue_with_y'])"
      ],
      "metadata": {
        "id": "maKToemcftMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_sm_cor_y"
      ],
      "metadata": {
        "id": "lAqz73wsf1KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h_sm_cor_y['rank_chi'] = h_sm_cor_y.groupby('group')['chi_with_y'].rank(ascending=False)\n",
        "h_sm_cor_y['rank_pv'] = h_sm_cor_y.groupby('group')['pvalue_with_y'].rank(ascending=True)\n",
        "# drop_h_cor_cols = list(set(h_cor_y[h_cor_y['rank'] > 1].x))"
      ],
      "metadata": {
        "id": "fEjCfGOef21Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_h_sm_cor_cols = list(set(h_sm_cor_y[h_sm_cor_y['rank_chi'] > 1].x))"
      ],
      "metadata": {
        "id": "Yw50-wKFgEOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_h_sm_cor_cols"
      ],
      "metadata": {
        "id": "pURiQbbngKSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for real world complex data, we found that we can group similarity category columns resonably\n",
        "# drop_cor_cols = drop_h_cor_cols+drop_h_sm_cor_cols"
      ],
      "metadata": {
        "id": "hcfdIpLcgLkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for this example, category columns not nessesary to remove multicollinearity\n",
        "drop_cor_cols = drop_h_cor_cols"
      ],
      "metadata": {
        "id": "LGI3dyUBglma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_cor_cols"
      ],
      "metadata": {
        "id": "5TC3xnAjg0y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=drop_cor_cols)"
      ],
      "metadata": {
        "id": "yYM8jUHJhF8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "VLpRIINQhIm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mppf1OcshNgw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}